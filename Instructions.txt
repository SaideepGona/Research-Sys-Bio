The python scripts listed here should generally not be run in isolation. Instead use the shell scripts to run the python
scripts automatically.

%%%%%%%%%%%%% SHELL SCRIPTS %%%%%%%%%%%%%%%

> > > GENERAL < < <

****batch_submit_err****
Starts a job instance of error_check.py with modifiable cluster parameters.

        ./batch_submit_err

****reset_all****
Cancels all jobs and clears files from NAS directory. Also launches jobs to clear scratch drives. Prepares for running
a new set of jobs.

        ./reset_all

> > > For ENCODE < < <

****batch_submit_scraper****    AND    ****batch_submit_scraper_pool****
Starts a job instance of encode_scraper with modifiable cluster parameters. One version is for the pool partition

        ./batch_submit_scraper <input file>

****start_job_series****
Runs a recipe of encode_scraper jobs by first partitioning the input file, running the specified number of jobs for
each partition, and finally an error checker.
NOTE: Need to set up input parameters for this since it is currently hardcoded

        ./start_job_series

> > > For GEO < < <

****batch_submit_geo_scraper****    AND    ****batch_submit_geo_scraper_pool****
Starts a job instance of encode_scraper with modifiable cluster parameters. One version is for the pool partition

        ./batch_submit_geo_scraper <input_file>

****start_geo_job_series****
Runs a recipe of geo_scraper jobs by first partitioning the input file, running the specified number of jobs for
each partition, and finally an error checker.
NOTE: Need to set up input parameters for this since it is currently hardcoded

        ./start_geo_job_series

%%%%%%%%%%%%% PYTHON SCRIPTS %%%%%%%%%%%%%%%

> > > GENERAL < < <

****error_check.py****
Checks .err and .out files in current directory for unusual file sizes. Halts all jobs if strange behavior instance
detected. Run one instance alongside any number of scraper instances.

        python3 error_check.py

****build_table.py****
Checks for annotation files and converts to .tfgene files (tf and genes to which they map). Then builds a full TF table.

        python3 build_table.py <upstream distance> <downstream distance>

****clean_scratch.py****
Cleans out the scratch directory for a given user

        python3 clean_scratch.py <user directory>


> > > For ENCODE < < <

****encode_scraper3.py****
Workhorse script. Collects and processes relevant input data from the encode database.

        python3 encode_scraper3 <input_file>

****partition_inputs.py****
Takes a full ENCODE input table and splits it into roughly equal subsegments by experiment. Expects "metadata.tsv".

        python3 partition_inputs.py <partition count>


> > > For GEO < < <

****geo_scraper3.py****
Workhorse script. Collects and processes relevant input data from the GEO database.

        python3 geo_scraper3 <input_file>

****partition_inputs_geo.py****
Takes a full GEO input table and splits it into roughly equal subsegments by experiment. Expects "metadata_geo.tsv".

        python3 partition_inputs_geo.py <partition count>

****geo_filter.py****
Takes output from Matt's geo-query code (series_data.tsv) and filters the data into a form usable by geo_scraper3.
THIS CAN AND SHOULD BE RUN STANDALONE

        python3 geo_filter.py <output file path> <input file path>


%%%%%%%%%%%%% DEPENDENCIES %%%%%%%%%%%%%%%

PYTHON3

BOWTIE2

SAMTOOLS

MACS2

HOMER

GEO-QUERY

SRA TOOLKIT